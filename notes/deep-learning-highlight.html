<article class="note">
  <h2 class="note-title">
    Deep Learning (highlight)
  </h2>
  <div class="content"><h1 id="deep-learning-highlight">Deep Learning (highlight)</h1>

<p><img src="https://img1.od-cdn.com/ImageType-100/0111-1/{13305220-BBAC-4F7F-9CCA-4F757C8D0854}Img100.jpg" alt="rw-book-cover" /></p>

<h2 id="metadata">Metadata</h2>

<ul>
<li>Author: <a href="john-d-kelleher.html">John D. Kelleher</a></li>
<li>Full Title: Deep Learning</li>
<li>Category: <span class="tag">books</span></li>
</ul>

<h2 id="highlights">Highlights</h2>

<ul>
<li>Machine learning involves a two-step process: training and inference (Location 182)</li>
<li>The encoded function is known as a model, and the analysis of the data in order to extract the function is often referred to as training the model (Location 184)</li>
<li>machine learning algorithms overcome the ill-posed nature of the machine learning task by supplementing the information provided by the data with a set of assumptions about the characteristics of the best function, and use these assumptions to influence the process used by the algorithm that selects the best function (or model). These assumptions are known as the inductive bias of the algorithm because in logic a process that infers a general rule from a set of specific examples is known as inductive reasoning. (Location 237)</li>
<li>just as in the real world, where there is no single best perspective that works in all situations, there is no single best inductive bias that works well for all datasets. This is why there are so many different machine learning algorithms: each algorithm encodes a different inductive bias. (Location 247)</li>
<li>The stronger the assumptions the less freedom the algorithm is given in selecting a function that fits the patterns in the dataset (Location 250)</li>
<li>In a sense, the dataset and inductive bias counterbalance each other: machine learning algorithms that have a strong inductive bias pay less attention to the dataset when selecting a function. (Location 251)</li>
<li>Finding a machine learning algorithm that balances data and inductive bias appropriately for a given domain is the key to learning a function that neither underfits or overfits the data, and that, therefore, generalizes successfully in that domain (Location 266)</li>
<li>Consequently, data scientists must use their intuition (i.e., make informed guesses) and also use trial-and-error experimentation in order to find the best machine learning algorithm to use in a given domain (Location 271)
<ul>
<li>Note: Is there any alternative solution?</li>
</ul></li>
</ul>

<p><span class="timestamp">Last update: 12/17/2023 09:58</span></p>
</div>
</article>

